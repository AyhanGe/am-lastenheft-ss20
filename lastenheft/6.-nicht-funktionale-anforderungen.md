# 6. Nicht-funktionale Anforderungen

## Wolfgang Cieplik (Unitechnik)
* Die Daten müssen aussagekräftig sein, damit man die Störungen Begründen kann und die Arbeit des Instandhaltungsmitarbeiter erleichtert.
* Die personenbezogenen Daten der Kunden dürfen nicht weitergegeben werden. Die Anforderungen der DSGVO sollen erfüllt werden.
## Thomas Unterbörsch, Torsten Winterberg (Opitz Consulting)

* Hohe Verfügbarkeits Themen, gewisse Ausfall Sicherheiten (Reliability).
* Datensicherheit (Backup)
* Mandantenfähigkeit
* Data Souvernity -> Daten von mehreren Unternehmen ist besser als einem Unternehmen: Hierbei ist die Datensicherheit sehr Wichtig. Denn Unternehmen möchten bei solchen Systemen sicher sein, ob Ihre Daten auch wirklich im Hub bleiben und nicht für andere Zwecke verwendet werden (“Geklaut werden”).
* Entweder Anonymisierung/Pseudonymisierung der Firmen spezifischen Daten, sodass der “Call” von der Firma nicht bekannt wird. Oder den Hub so kapseln , dass die Daten nicht woanders gelangen.
* Die API muss flexibel zu verschiedene Maschinen Daten sein, diese können IOT Geräte sein oder auch generell Maschinen die sehr viele Sensordaten liefern. Es muss also die Möglichkeit bestehen, das solche Daten problemlos in die API geschickt werden können.
* Deshalb braucht man zusätzlich eine Dynamische Lösung wo die ganzen “neuen” Daten mittels Datenmanagement gesteuert wird. Für einen Menschen wäre dies zu viel Aufwand und man müsste viel Zeit dafür investieren bis herausgefunden wurde zu welcher Maschine diese Daten gehören usw.
* Zum Thema Datenspeicherung muss erstmal herausgefunden werden, welche dieser Daten “kurzfristig” gespeichert werden und welche langfristig, um bspw. solche Daten für Anomalie Erkennungen etc. verwenden kann.
### Usability
* Opitz Consulting würde kein riesen Wert auf Usability legen, denn deren Mitarbeiter sich mit IT System schon relativ gut auskennen.
* Andere Mitglieder des Projekts, wie z.B. Maschinenbau und Co. werden hierbei sicherlich bestimmte Anforderungen haben (Weil Sie eben kein IT Know How haben). Hierbei muss sichergestellt werden, dass das ganze “Dummie” Sicher ist.-> Bedienbarkeit und Erlernbarkeit des Systems hohen Wert setzen.
### Performance
* Es wurde von der Siemens SPS Messwerten abgefragt die von den Opitz Server alle 200ms gesampelt hat. Selbst das sind schon unfassbare Daten und das alles für einen einzigen Sensor. Will man das alles in der Plattform haben ? Ja,Nein -> Diese * Performance Fragen soll laut Opitz gelöst werden.
* Zeitreihen Speicherung, muss extrem schnell messwerte aufnehmen
###  Supportability
*   Stabile bausteine
*   Stabile Frameworks
* keine uralten Frameworks verwenden
### Design for Change
* Die Architekturkonzepte die verwendet werden sollen flexibel sein, so dass man auch nach zwei Jahren ein ganz anderes System haben kann.
* Lambda Architektur /Kappa-Architektur  könnte man verwenden
### Datenschutz
* Wenn es personen bezogene Daten gibt, muss die Datenschutz auf jeden fall gewährleistet werden.
* Nächste Frage wäre ob die Firmen die Daten in die Plattform abgeben, auch Daten  von anderen Firmen sehen können. Da kommt man wieder zum Thema Anonymisierung etc.
* Die ganze Problemstellung ist weg, wenn man in der ersten Phase erstmal nur Maschinendaten verwendet. Opitz wäre in der ersten Phase hierfür.
## Prof. Dr. Pyschny
* Software-Systeme mit ihren Schnittstellen in die Data Platform zu integrieren.
* komplexe Optimierungsprobleme zu lösen. Welche verschiedene Prozessdaten erzeugen, welche für unterschiedliche Szenarien genutzt werden können und aus diesem Grund für uns auch interessant sind. Die Data Platform soll uns eine Infrastruktur bieten, welche es uns ermöglicht, diese Prozessdaten bei Versuchen mit Maschinen aufzuzeichnen, damit diese ausgewertet werden können.
* Erzeugte Daten können aus unternehmerischer Sicht genutzt werden, um Aufträge strukturiert auf Produktionseinrichtungen zu planen, interessant sind dabei Belegungszeiten, Kapazitäten und Prozessdauern.  Eine weitere Sicht ist die algorithmische Umplanung der vorhandenen Aufträge, hierfür wird allerdings eine starke Transparenz der Produktion sowie der Aufträge benötigt. Eine weitere Kategorie ist die Qualitätssicherung sowie die Prozessoptimierung durch verschiedene Prozessdaten wie z.B Temperaturen, Kräften, Schwindungen sowie Geschwindigkeiten.
* Smart factory: Maschinenvernetzung, cyberphysische Systeme, selbststeuernde Produktion ist maßgeschneidert für unsere Fakultät. Mich würde es freuen, wenn wir das mit dem Innovation Hub irgendwie in diese Richtung hinbekommen würden. 
* Montage 4.0 besteht für mich speziell aus zwei Themen. Als erstes die Einbindung des Menschen in ein System von automatisierten Einheiten. Dem Menschen sollen die Informationen zur Verfügung gestellt werden, welche er auch braucht. Außerdem soll er unterstützt werden, die richtigen Entscheidungen zu treffen.  
Für Dokumentation und Kontrollzwecke soll es eine Wahrnehmungsunterstützung für den Menschen geben. Diese Daten sollen allerdings nicht nur gespeichert, sondern auch aufbereitet werden. Für mich ist klar, dass diese Daten am Ende gesammelt werden, für mich ist aber auch klar, dass es für diesen Vorgang auch bestehende Systeme gibt. Was mir nicht klar ist, ist welche Rolle die Data Platform für das Hub oder die Modellfabrik überhaupt einnehmen soll. Soll das eine integrierende Platform sein, wo Daten aus einzelnen Systemen zusammengeführt werden? Oder soll es die alles sammelnde Datenplattform sein wo sämtliche Maschinen ihre Daten reinschubsen? Geht’s also gar nicht zentral um die Maschinen? Fragen über Fragen. Ich habe versucht mir ein gewissen Bild zu erarbeiten, wie die IT Infrastruktur von einem produzierenden Unternehmen in der Ausbaustufe aussieht, was genau für IT Systeme dort im Einsatz sind und welche Herausforderungen dort existieren, diese zu vernetzen. Die Data Platform kann diese Lücke füllen und beispielsweise über ein virtuelles Produktionsabbild agieren und unterstützen. Das wäre meine Vorstellung der Leistungen der Data Platform.
* Erfassung von Prozessdaten, also die Erfassung von Informationen aus der Produktion. 
## Thomas Brück, Geschäftsführer Fa. STRIKO
* Effizienz und Zeitverhalten: Effizienz in bezug auf Zeitverhalten muss auch bei vielen anfallenden Daten gegeben sein. Eine Berstscheibe hat bspw. eine Ansprechzeit von 8ms bis 15ms.
* Effizienz und Ressourcenverbrauch: Die Übermittlung der Daten muss auch bei geringer Bandbreite gewährleistet werden. Durch die Übermittlung dürfen andere Prozesse nicht beeinträchtigt werden.
* Funktionalität und Sicherheit: Vertrauliche Kundendaten müssen vor unbefugtem Zugriff geschützt sein.
* Zuverlässigkeit und Reife: Das System muss gut etabliert sein, damit große Konzerne zum mitmachen animiert werden.
* Gebrauchstauglichkeit und Attraktivität: Das System muss einen Mehrwert für die Datenbereitsteller bringen, damit diese auch Daten herausgeben.
* Funktionalität und Angemessenheit: Die Plattform regt unternehmen an, ihr wissen zwischen Teilnehmern zu teilen.
* Funktionalität und Angemessenheit: Das Innovation Hub, sollte Beratung für IT-Lösungen geben.




